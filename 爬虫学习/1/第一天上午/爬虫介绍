1.具体的参照可以查看印象笔记1.0、1.1

数据从哪来？
有一些第三方的数据平台，负责收集数据
整理数据，提供给消费者。比如：数据堂

开放的平台，可以供我们拿取数据的，
中国人口普查网，其他的免费的数据平台。

我们还可以自己去获取数据？
如何去获取数据？ 爬虫。。。

如何定义爬虫？
爬虫是一个自动的从互联网爬取网页数据的程序（脚本）

网页的几大特性：
1.首先url（统一资源定位符），是唯一的。
2.网页展示是使用的html（超文本），我们要获取数据久存在HTML中
3.我们通过http/https来访问网页

python？
其实在爬虫界，有很多语言可以做爬虫？
java、C、PHP、
PHP：被业界叫做世界上最好语言，常用做开发后台程序，
他也可以做爬虫，但是它对多线程、多任务的处理能力不强。

java：有很长一段历史了，使用的人也比较多，意味着它
的生态圈比较完善，各种库和各种问题的解决办法，它其
实是python最大的竞争对手，java代码比较冗余，后期
的修改不方便，假如网站发生变化，那么重构的代价比较大

C：可定能够写爬虫的，而且用C语言写出来的程序运行的
效率非常高，C语言是一种底层的语言，一般很少有人能
够精通，如果你们能够使用C语言来写爬虫的话，可以
出去装个B了

最终定义了使用Python语言来开发爬虫？
语言优美，代码简介、又丰富的三方模块，并python是
一门胶水语言，它可以使用一些三方就能够调用其他语言
模块。

我们要实现一个爬虫其实有几个大步骤：
1.首先我们要确定的是我们的目标url。
2.拿到url之后，我们要发起请求->服务器根据请求做出响应
3.拿到响应之后，根据你想要的目标数据去做提取。
  a）.提取到你想要的数据
  b）.新的url，然后再执行第二步，不停的执行，直到没有新的url（这时候标志者爬虫结束）
以上就是一个简单的爬虫的思路

1.爬虫的分类：其实是分为两大类的：

a.通用爬虫：（是为搜索引擎而生的）尽可能的去爬取胡良网上的数据
（拿到数据之后会做一个数据的清洗、分词等等操作）

特点：
1.获取全网的所有数据，没有明确的目标，有新的url就提取
2.它是为搜索引擎服务的
3.当我们使用搜索引擎去做塞选的时候，会返回很多无关数据（可能不是你想要的数据）

通用爬虫：如何知道有新的url产生呢？
1.通过其他网页的外链
2.很多搜索引擎公司会跟DNS或者能够生成域名
的服务商合作，如果与新的域名产生，那么这些
服务商就会把新的链接给搜索引擎，让它去爬取数据

通用爬虫获取网页的时候也是有一定的优先级
1.第一是根据用户点击量，也是就根据流量去做权重
2.第二种是根据竞价排名（是花钱你能够买到的）

这个时候就产生了另一种爬虫
聚焦爬虫：有目的、有针对行的去互联网获取数据。
1.为小型的平台、或者垂直领域的公司服务，有目的性的去抓取数据
2.这时候获取到的数据，就是明确的，是根据我们想要的目标去提取的。










